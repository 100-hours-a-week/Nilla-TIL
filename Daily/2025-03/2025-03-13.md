## 날짜: 2025-03-13

### 스크럼
- EKS 활용해보기

### 새로 배운 내용
#### EKS로 2048 게임 띄우기
1. 리전은 버지니아 북부로(통일만 한다면 상관 없음), VPC 자동 생성 활용해 퍼블릭 서브넷 두개, 프라이빗 서브넷 두개를 생성한다. 
   - 로드밸런서 구분을 위한 태그를 설정한다. 
   - 퍼블릭 서브넷 태그 - key:kubernetes.io/role/elb | value: 1
   - 프라이빗 서브넷 태그 - key:key:kubernetes.io/role/internal-elb | value: 1

2. EKS를 생성한다. 
   - 클러스터 버전 1.29, 권장 생성 롤로 지정, eks api 및 Config map 설정
   - 트러블 슈팅: 이 경우 config map에 iam이 지정되어 있어야 하므로, 클러스터를 만들 때부터 해당 iam 사용자로 로그인해서 만드는 것이 좋다. api 로그인이 안될 때가 있다.
   - 서브넷은 생성한 서브넷 모두를 지정(퍼블릭+프라이빗)
   - 클러스터 엔드포인트 : 프라이빗으로 지정
   - CoreDns,kube-proxy,Amazon VPC CNI,Amazon EKS Pod Identity,Amazon GuardDuty EKS 지정
   - eks cluster 보안그룹에서 모든 트래픽 인바운드를 허용한다.

3. Bastion Host 용도의 EC2를 생성하고, 접속한다.
   - 보안그룹은 인바운드-SSH 허용, 아웃바운드-모든 트래픽 허용
   - Amazon linux 사용한다.

4. EKS node group을 생성한다.  
   - 서브넷은 프라이빗 서브넷만 선택.

5. cli 서비스 설치
    ```bash
    curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    unzip awscliv2.zip
    sudo ./aws/install
    aws --version
    ```
6. k8s 설치
    ```bash
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    chmod +x kubectl
    sudo mv kubectl /usr/local/bin/
    kubectl version --client
    ```

7. eksctl 설치
   ```bash
    curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
    sudo mv /tmp/eksctl /usr/local/bin
    eksctl version
    ```

8. aws 로그인 및 환경변수 설정
    ```bash
    aws configure
    
    eks_cluster_name= 클러스터 이름
    region_name= 리전 입력
    role_name=Custom_EKS_LBC_Role-$eks_cluster_name
    account_id=$(aws sts get-caller-identity --query 'Account' --output text)
    ```

9. AWS CLI를 사용하여 지정한 EKS 클러스터에 접근할 수 있도록 로컬 kubeconfig 파일을 업데이트
    ```bash
    aws eks --region $region_name update-kubeconfig --name $eks_cluster_name
    # kubectl이나 다른 Kubernetes 클라이언트가 해당 EKS 클러스터와 통신할 때 필요한 인증 정보와 API 서버의 엔드포인트를 kubeconfig 파일에서 읽어올 수 있다

    eksctl get nodegroup --cluster $cluster_name --region $region
    ```

10. helm 설치
    ```bash
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

    helm version
    ```

11. OIDC 공급자 설정, OIDC 공급자 연결
    ```bash
    oidc_id=$(aws eks describe-cluster --region $region_name --name $eks_cluster_name --query "cluster.identity.oidc.issuer" --output text | cut -d '/' -f 5)
    aws iam list-open-id-connect-providers | grep $oidc_id | cut -d "/" -f4

    eksctl utils associate-iam-oidc-provider --cluster $eks_cluster_name --approve
    aws iam list-open-id-connect-providers | grep $oidc_id | cut -d "/" -f4
    ```

12.  IAM 정책 파일 다운로드 및 정책 생성
     ```bash
       curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.3.1/docs/install/iam_policy.json
        aws iam create-policy \
        --policy-name AWSLoadBalancerControllerIAMPolicy \
        --policy-document file://iam_policy.json

     ```

13. IAM 서비스 어카운트 생성
    ```bash
    eksctl create iamserviceaccount \
    --cluster=${eks_cluster_name} \
    --namespace=kube-system \
    --name=aws-load-balancer-controller-${eks_cluster_name}2048-c\
    --role-name ${role_name}2048-r\ 
    --attach-policy-arn=arn:aws:iam::${account_id}:policy/AWSLoadBalancerControllerIAMPolicy \
    --approve

    #뒤의 2048-r과 2048-c는 name과 rolename 구분용도로 임의로 붙인 것이므로
    #구분만 된다면 어떤 문자를 작성해도 상관 없다.

    ```
    트러블 슈팅: 해당 단계에서 만든 iam 계정에 로드밸런서 관련 접근 권한을 추가로 줘야 이후 로드밸런서 생성 단계(15번)에서 오류가 발생하지 않음! (콘솔로 들어가서 ${role_name}2048-r 역할을 찾고, 해당 역할에 full access 혹은 필요한 권한을 부여해야함.) 

    주지 않으면 로드밸런서 파드 로그에 다음과 같은 오류가 나타남.
    ```
    Warning  FailedDeployModel  5m23s                  ingress  Failed deploy model due to operation error Elastic Load Balancing v2: CreateTargetGroup, https response error StatusCode: 403, RequestID: 0437f97a-6731-4314-a051-f7f7eb2a9d2e, api error AccessDenied: User: arn:aws:sts:::assumed-role/Custom_EKS_LBC_Role2048-eks-nilla-20480314-r/1741935019030729865 is not authorized to perform: elasticloadbalancing:AddTags on resource: arn:aws:elasticloadbalancing:us-east-1::targetgroup/k8s-game2048-service2-b71eb3eb26/* because no identity-based policy allows the elasticloadbalancing:AddTags action
    ```

14. Helm 리포지토리 추가 및 업데이트
    ```bash
    helm repo add eks https://aws.github.io/eks-charts
    helm repo update
    ```

15. AWS Load Balancer Controller 설치
    ```bash
    helm install aws-lb-controller eks/aws-load-balancer-controller \
    -n kube-system \
    --set awsRegion=$region_name \
    --set awsVpcID=$cluster_vpc_id \
    --set clusterName=$eks_cluster_name \
    --set serviceAccount.create=false \
    --set serviceAccount.name=aws-load-balancer-controller-${eks_cluster_name}2048-c
    #위에서 서비스 어카운트 네임을 바꿨다면 2048-c 부분도 변경해야 한다. 

    kubectl get pods -n kube-system -l [app.kubernetes.io/name=aws-load-balancer-controller](http://app.kubernetes.io/name=aws-load-balancer-controller)
    #pod가 안나온다면 제대로 생성되지 않은 것이다. (보통 환경 변수 미입력으로 인한 오류)

    ```


16. AWS Load Balancer on EKS
    ```bash
    kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/examples/2048/2048_full.yaml

    kubectl get ingress/ingress-2048 -n game-2048
    ```
    이 과정에서 로드밸런서 프로비저닝 등의 이유로 dns 부여에 시간이 걸릴 수도 있다. 정상적으로 모든 pod가 run 되고 있다면, 3~5분 정도 기다리면 dns 주소가 발급된다. 

    pod가 crash 등의 오류가 발생하며 재시작 중이라면, 대부분 환경변수 오기입 또는 권한 문제이므로 문제가 생긴 pod의 log를 확인하여 해결하면 된다. 


<img src= img/38.png>
원활히 플레이 가능했다!


### 오늘의 회고
- 사실 두번 정도 생성에 실패했는데, 대부분 iam 권한 오류로 생긴 문제들이었다. 이후 관련 설정들을 바꿔가며 차근차근 도전했더니 해결할 수 있었다. 당연히 최대 권한으로 주면 실습은 해결할 수 있겠지만, 최소 권한을 주기 위해서 각 권한들을 공부해야겠다는 생각이 들었다. 

### 참고 자료 및 링크
- x