## 날짜: 2025-02-19

### 스크럼
- 쿠버네티스 : 서비스
  
### 새로 배운 내용
#### (13-0) 서비스 개념 정리
- 서비스 : 파드들을 그룹화하고, 클러스터 내 트래픽을 이 파드들로 라우팅하는 네트워크 접근점 오브젝트
- 파드는 일시적인 존재이므로, 언제든 할당된 ip가 동적 변경이 가능하다. 따라서 서비스에 고정된 ip 주소와 dns 이름을 제공, 파드에 대한 접근과 로드밸런싱이 가능하게 한다.
- *Headless Service :
    - **ClusterIP 없이** 생성되는 서비스로, **서비스 IP를 제공하지 않음**.
    - 주로 **StatefulSet**과 함께 사용되며, **각 파드의 IP를 DNS로 제공**하여 **파드에 직접 접근.**
    - **DNS 레코드**를 통해 **파드 이름**을 통해 **파드에 직접 접근**할 수 있도록 함.
- kube-proxy :
    - **트래픽 라우팅**을 담당. **iptables** 또는 **ipvs**를 사용하여 서비스 IP로 들어오는 요청을 **파드로 전달**
    - 파드에 **네트워크 트래픽을 분배**하고, 여러 파드로 **로드 밸런싱**을 수행
    
    ---
    
    | 서비스 타입 | 접근 가능 범위 |
    | --- | --- |
    | ClusterIP (기본) | - 내부 클러스터 통신에 사용됨. 클러스터 내부의 파드에서 서비스의 이름으로 접근 가능 <br>- 내부 DNS에 등록한 일음으로 파드 집합에 요청 전송을 한다. <br>- 매니페스트에 clusterIP:None 이라고 지정하면 헤드리스* 설정으로 서비스가 작동함 <br>- 외부에서 접근 불가, 클러스터 내에서만 유효한 IP <br>- 개념 헷갈려서 질문 남김 : [ClusterIP의 부하분산](https://www.notion.so/ClusterIP-19f394a4806180698c02e79bfbb31415?pvs=21)  |
    | NodePort | - ClusterIP의 접근 범위뿐 아니라, K8s 클러스터 외부에서도 접근 가능 <br>- <노드 ip>:<NodePort> 형식으로 특정 포트를 개방하여 접근 가능함 <br>- 공개 포트번호의 범위는 기본적으로는 30000~32767<br>- 노트포트 타입 서비스를 만들면, 클러스터의 모든 노드에 지정한 포트가 오픈된다!<br>- 각 노드가 수령한 요청은 대상 파드들에 부하분산되긴 하지만, 로드밸런서를 쓰는게 낫다.<br>- 외부 트래픽을 클러스터로 유도하는 방식으로 서비스 노출 |
    | LoadBalancer | - NodePort 접근 범위뿐 아니라 K8s 클러스터 외부에서 대표 IP 주소로 접근 가능<br>- 클라우드 환경에서 외부 로드 밸런서를 사용, 외부 트래픽을 서비스로 유도<br>- 서비스는 동적으로 외부 IP와 포트를 할당받고, 로드밸런서는 트래픽을 여러 파드로 분배하는 역할을 한다. <br>- nodeport를 사용하기 때문에 clusterIP도 자동할당 된다.  |
    | ExternalName | - K8s 클러스터 내의 파드에서 외부 IP 주소(외부의 엔드포인트)에 서비스의 이름으로 접근 가능<br>- 퍼블릭 클라우드의 데이터베이스나, 인공지능 OpenAPI 서비스 등을 접근할 때 사용<br>- 서비스의 이름과 외부 DNS 이름의 매핑을 내부 DNS에 설정한다.<br>- 외부 서비스의 **포트를 지정**할 수 없고, 오직 **도메인 이름만** 사용. 실제 포트 번호는 클라이언트(파드)가 직접 관리하거나, 외부 서비스에서 사용하는 기본 포트를 사용해야 함. |
  
#### (13-1) 서비스 생성 & 기능 확인 (실제 실습)
- 서비스는 요청을 전송할 파드를 셀렉터의 라벨과 일치하는 파드로 **etcd**로부터 선택한다.
- 셀렉터와 디플로이먼트 파드 템플릿의 ‘metadata.label’에 같은 값을 설정하면 된다.
- ports쪽에 다음과 같은 사항의 지정이 가능하다.
    - name(포트가 하나라면 생략 가능)
    - port(필수, 포트 번호)
    - protocol(생략시 tcp)
    - nodePort(생략시 시스템이 자동 할당. nodeport나 loadbalancer라면 모든 노드에서 포트가 동개되며, 설정 포트가 이미 사용 중이라면 오브젝트 생성에 실패한다.)
    - targetPort(생략시 port와 같은 값. selector에 의해 대응하는 파드가 공개하는 포트 번호 혹은 포트 이름을 설정)
- 디플로이먼트, 서비스 파일 생성
    
    ```yaml
    #서비스 svc.yml
    apiVersion: v1
    kind: Service
    metadata:
     name: web-service #네임스페이스 내 유일한 이름. 내부 dns에 등록되며 이후 기동된 파드의 환경 변수에 설정
    spec: #여기에 type(클러스터ip, 노드포트, 로드밸런서...) 설정 가능. 지금은 생략하여 clusterip 자동 적용
    #세션 어피니티(클라이언트의 요청이 항상 동일한 파드로 라우팅되도록 보장하는 기능)설정 가능
    #clusterIP 설정 생략시 대표 ip 주소가 자동으로 할당하며, none이라면 헤드리스로 동작
     selector: #service - 백엔드 pod와 연결
      app: web
     ports: #name, port(번호), protocol, nodePort, targetPort 지정 가능
     - protocol: TCP 
       port: 80
    
    #디플로이먼트 deploy.yml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
     name: web-deploy
    spec:
     replicas: 3
     selector: #deployment - pod 대응용
      matchLabels:
       app: web
     template: #파드 템플릿
      metadata:
       labels:
        app: web #파드의 라벨
      spec:
       containers:
       - name: nginx
         image: nginx:latest
    ```
    
- 오브젝트 생성 후 상태 출력 & 대화형 컨테이너로 요청
    
    ```bash
    
    kubectl apply -f deploy.yml
    kubectl apply -f svc.yml 
    
    #오브젝트 생성 후 살펴보면 포드들이 만들어진 모습을 볼 수 있다.   
    **kubectl get all | grep web**
    pod/web-deploy-66fbbff65d-5lgpk   1/1     Running     0          9m38s
    pod/web-deploy-66fbbff65d-d6xt6   1/1     Running     0          9m38s
    pod/web-deploy-66fbbff65d-dwvk4   1/1     Running     0          9m39s
    #웹 서비스도 clusterip로 잘 지정되었다. 
    service/web-service   ClusterIP   10.104.123.59   <none>        80/TCP    8m47s
    deployment.apps/web-deploy   3/3     3            3           9m39s
    replicaset.apps/web-deploy-66fbbff65d   3         3         3       9m39s
    
    #busybox로 직접 접근해서 살펴볼 수도 있다.
    kubectl run -it busybox --restart=Never --rm --image=busybox sh
    
    #wget으로 요청하면
    / **# wget -q -O - http://web-service   <(dns에 등록된 이름)**
    <!DOCTYPE html>
    <html>
    <head>
    <title>Welcome to nginx!</title>
    <style>
    ... #nginx의 html이 불러와진다. 이하 생략
    
    #환경 변수를 살펴보면 잘 접근하고 있는걸 볼 수 있다.
    **/ # env | grep WEB_SERVICE**
    WEB_SERVICE_PORT=tcp://10.104.123.59:80
    WEB_SERVICE_SERVICE_PORT=80
    WEB_SERVICE_PORT_80_TCP_ADDR=10.104.123.59
    WEB_SERVICE_PORT_80_TCP_PORT=80
    WEB_SERVICE_PORT_80_TCP_PROTO=tcp
    WEB_SERVICE_PORT_80_TCP=tcp://10.104.123.59:80
    WEB_SERVICE_SERVICE_HOST=10.104.123.59
    ```
    
- index.html 호스트명 작성, 부하분산 확인
    
    ```bash
    for pod in $(kubectl get pods | awk 'NR>1 {print $1}' | grep web-deploy); do kubectl exec $pod -- /bin/sh -c "hostname > /usr/share/nginx/html/index.html"; done
    #pod 목록을 가져와서 / 첫줄을 건너뛰고(nr>1)두번째 줄부터 데이터를 처리함. 각 줄의 첫 컬럼(파드이름)을 출력하게 한다.
    #grep으로 web-deploy인 파드 이름만 가져온다.
    #각 파드에 대해 exec으로 들어가서 hostname 명령어를 실행하고, 그 결과(호스트의 이름)를 /usr/share/nginx/html/index.html 파일에 덮어쓴다.
    #제대로 작업이 이루어지면 각 파드의 호스트네임을 웹 브라우저에서 확인 가능하다.
    
    #이상태로 다시 wget을 해본다면?
    kubectl run -it busybox --restart=Never --rm --image=busybox sh
    / # while true; do wget -q -O - http://web-service; sleep 1; done
    web-deploy-66fbbff65d-dwvk4
    web-deploy-66fbbff65d-d6xt6
    web-deploy-66fbbff65d-5lgpk
    web-deploy-66fbbff65d-d6xt6
    web-deploy-66fbbff65d-d6xt6
    web-deploy-66fbbff65d-d6xt6
    web-deploy-66fbbff65d-5lgpk
    web-deploy-66fbbff65d-d6xt6
    web-deploy-66fbbff65d-dwvk4
    web-deploy-66fbbff65d-d6xt6
    
    #어떤 호스트가 wget을 받고 있는지 확인이 된다. 부하분산이 이루어지고 있는 걸 알 수 있다. 
    ```
    
- sessionAffinity - 한 세션을 유지하고 싶을 때
    
    ```bash
    #yml에 다음과 같은 사항을 추가한다. 
    sessionAffinity: ClientIP
     sessionAffinityConfig:
       clientIP:
         timeoutSeconds: 60
         
     #이후 위와 같이 테스트하면, 한 호스트로만 접속하는 모습을 볼 수 있다.
    kubectl get service
    NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
    kubernetes    ClusterIP   10.96.0.1       <none>        443/TCP   2d5h
    web-service   ClusterIP   10.104.123.59   <none>        80/TCP    56m
    
    kubectl get pod | grep web
    web-deploy-66fbbff65d-5lgpk   1/1     Running     0          58m
    web-deploy-66fbbff65d-d6xt6   1/1     Running     0          58m
    web-deploy-66fbbff65d-dwvk4   1/1     Running     0          58m
    
    kubectl run -it busybox --restart=Never --rm --image=busybox sh
    **/ # while true; do wget -q -O - http://web-service; sleep 1; done
    web-deploy-66fbbff65d-dwvk4
    web-deploy-66fbbff65d-dwvk4
    web-deploy-66fbbff65d-dwvk4**
    ```
    
- Nodeport 사용
    
    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: node-port
    spec:
      type: NodePort     # type 추가
      ports:
      - port: 8080
        protocol: TCP
        targetPort: 80
        nodePort: 30080  # 호스트(노드)의 포트 지정
      selector:
        run: node-port
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      labels:
        run: node-port
      name: node-port
    spec:
      containers:
      - image: nginx
        name: nginx
        ports:
        - containerPort: 80
    ```
    
    ```bash
    kubectl apply -f svc-np.yml
    kubectl apply -f pod-np.yml
    
    #제대로 nodeport로 생성되었다.
    kubectl get svc
    NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
    kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP          2d5h
    node-port    NodePort    10.97.190.203   <none>        8080:30080/TCP   2m53s
    
    #clusterip로 접근하려고 하니 안되었다. 왜지?
    **curl http://10.97.190.203:30080** 
    
    #nodeport의 경우 외부에서 접근하려면, clusterip가 아닌 노드 ip로 접근해야하기 때문.
    #노드 정보를 불러오면 ip를 알 수 있다. 
    kubectl get nodes -o wide
    NAME       STATUS   ROLES           AGE    VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
    minikube   Ready    control-plane   2d5h   v1.32.0   192.168.49.2   <none>        Ubuntu 22.04.5 LTS   6.8.0-1021-aws   docker://27.4.1
    
    #nginx html을 잘 불러오는 모습을 볼 수 있다.
    curl http://192.168.49.2:30080 
    <!DOCTYPE html>
    <html>
    <head>
    <title>Welcome to nginx!</title>
    <style>
    ... #생략
    
    ```
    
- 로드밸런서 사용
    
    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: load-bal
    spec:
      type: LoadBalancer  # 타입 LoadBalancer
      ports:
      - port: 8080
        protocol: TCP
        targetPort: 80
        nodePort: 30088   # 30088로 변경
      selector:
        run: load-bal
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      labels:
        run: load-bal
      name: load-bal
    spec:
      containers:
      - image: nginx
        name: nginx
        ports:
        - containerPort: 80
    ```
    
    ```bash
    kubectl apply -f svc-lb.yml
    kubectl apply -f pod-lb.yml
    
    kubectl get svc
    NAME         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
    kubernetes   ClusterIP      10.96.0.1        <none>        443/TCP          2d5h
    load-bal     LoadBalancer   10.101.245.108   <pending>     8080:30088/TCP   14s
    
    **kubectl describe svc load-bal**
    
    Type:                     LoadBalancer
    Port:                     <unset>  8080/TCP
    TargetPort:               80/TCP
    
    #아마 로컬 환경에서 돌아가고 있어서, 로드밸런서 서비스가 ip를 할당해주지 않는 문제 때문인듯
    curl http://192.168.49.2
    curl: (7) Failed to connect to 192.168.49.2 port 80 after 0 ms: Couldn't connect to server
    
    #nodeport로는 접근 가능하다.
    ubuntu@ip-172-31-25-87:~$ curl http://192.168.49.2:30088
    <!DOCTYPE html>
    <html>
    <head>
    ... 
    ```
    
- Externalname
- 외부 DNS 주소에 클러스터 내부에서 사용할 새로운 별칭을 정하고, 별칭을 이용해 연결한다.
    
    ```yaml
    #External.yaml
    
    apiVersion: v1
    kind: Service
    metadata:
      name: google-svc  # 별칭
    spec:
      type: ExternalName
      externalName: google.com  # 외부 DNS
    ```
    
    ```bash
    kubectl apply -f external.yml 
    
    #파드를 생성한뒤, curlimages/curl 이미지를 사용하여 google-svc 서비스에 HTTP 요청을 보냄
    #-H "Host: google.com"은 google.com을 요청하는 헤더를 추가한 것. google-svc 서비스 요청을 구글의 호스트로 포워딩함
    **kubectl run call-google --image curlimages/curl \
    -- curl -s -H "Host: google.com" google-svc**
    
    #http://www.google.com/ 으로 리다이렉션 하라는 요청 받음
    **kubectl logs call-google**
    <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
    <TITLE>301 Moved</TITLE></HEAD><BODY>
    <H1>301 Moved</H1>
    The document has moved
    <A HREF="http://www.google.com/">here</A>.
    </BODY></HTML>
    ubuntu@ip-172-31-25-87:~$ 
    ```
    
    🤔 의문: google-svc는 결국 별칭을 사용하기 위함인데 헤더(**-H "Host: google.com"**)가 필요하다면 왜 쓰는걸까?? : 내부 애플리케이션에서 외부 리소스를 마치 클러스터 내 리소스처럼 사용하기 위해서. 예를 들자면 다음과 같이 쓸 수도 있다.
    
    ```bash
    const axios = require('axios');
    
    // `google-svc`를 사용하여 `google.com`에 요청 보내기
    axios.get('http://google-svc')
      .then(response => {
        console.log('Response from google.com:', response.data);
      })
      .catch(error => {
        console.error('Error:', error);
      });
    ```
    
- 서비스 ip 주소 조회하기
    
    ```yaml
    **kubectl run client --image nginx #nginx 이미지로 클라이언트 파드를 만든다. 
    #서비스에게 요청을 하기 위해 만든 파드라고 생각하면 된다!
    kubectl get svc**
    NAME         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
    kubernetes   ClusterIP      10.96.0.1        <none>        443/TCP          2d6h
    load-bal     LoadBalancer   10.101.245.108   <pending>     8080:30088/TCP   55m
    
    #dns lookup을 하기 위해 nslookup을 설치해준다.
    **kubectl exec client -- sh -c "apt update && apt install -y dnsutils"**
    
    #load-bal 서비스의 DNS를 조회한다. 
    **kubectl exec client -- nslookup load-bal**
    ;; Got recursion not available from 10.96.0.10
    Server:         10.96.0.10
    Address:        10.96.0.10#53
    
    **Name:   load-bal.default.svc.cluster.local
    Address: 10.101.245.108**
    ;; Got recursion not available from 10.96.0.10
    
    #다른 방식의 조회도 있다.
    #<서비스이름>
    #<서비스이름>.<네임스페이스>
    #<서비스이름>.<네임스페이스>.svc.cluster.local
    kubectl exec client -- nslookup **load-bal.default.svc.cluster.local**
    kubectl exec client -- nslookup **load-bal.default**
    ```
    
- clusterip(심화) : 그냥 위에처럼 생략해서 써도 cluster-ip가 되지만, 다음과 같이 길게 쓸 수도 있다.
    
    ```yaml
    # Service 정의: 클러스터 내에서 nginx 서버에 대한 접근을 관리
    apiVersion: v1
    kind: Service
    metadata:
      creationTimestamp: null
      name: cluster-ip  # 서비스 이름, 클러스터 내에서 사용
    spec:
      ports:
      - port: 80  # 클러스터 내에서 서비스가 사용할 포트 번호
        protocol: TCP  # 사용할 프로토콜 (TCP)
        targetPort: 80  # 파드 내에서 실제로 요청을 처리할 포트 번호 (nginx의 기본 포트)
      selector:
        run: cluster-ip  # 이 서비스가 연결할 파드를 선택하는 라벨 (아래의 파드와 일치해야 함)
    status:
      loadBalancer: {}  # LoadBalancer가 설정되지 않았으므로 빈 객체 (로컬 환경에서 사용 시, 실제 로드밸런서는 사용되지 않음)
    ---
    ---
    # Pod 정의: nginx 서버를 실행하는 파드
    apiVersion: v1
    kind: Pod
    metadata:
      creationTimestamp: null
      labels:
        run: cluster-ip  # 이 파드는 'run: cluster-ip' 라벨을 가지고 있어, 위의 서비스에서 연결될 파드
      name: cluster-ip  # 파드 이름
    spec:
      containers:
      - image: nginx  # nginx 이미지를 사용하여 컨테이너 실행
        name: cluster-ip  # 컨테이너 이름
        ports:
        - containerPort: 80  # nginx 컨테이너의 80번 포트에서 요청을 수신
        resources: {}  # 리소스 제한 없음 (기본 설정)
      dnsPolicy: ClusterFirst  # DNS 요청을 클러스터 DNS로 먼저 처리
      restartPolicy: Always  # 파드가 종료되면 항상 재시작
    status: {}  # 파드의 상태 (현재는 비어 있음)
    
    ```
    
#### (13-2) 서비스 동작 원리(+ 쿠버네티스의 동작 방식)
- **쿠버네티스 전반적인 작동 과정**
    1. **파드 생성**: 파드가 생성되면 **서비스가 파드를 자동으로 감지**하고, 해당 파드에 트래픽을 라우팅할 수 있도록 설정
    2. **서비스 생성**: 서비스가 생성되면, **고정된 IP**와 **DNS 이름**을 할당받고, **kube-proxy**가 이 서비스에 대한 트래픽을 **관련 파드들로 전달**
    3. **트래픽 라우팅**: 서비스로 들어오는 요청은 **kube-proxy**를 통해 **적절한 파드**로 분배되며, **로드 밸런싱**을 수행
    4. **클러스터 내 통신**: 클러스터 내 다른 파드는 서비스의 **DNS 이름**을 사용하여 해당 서비스에 요청을 보냄
    
1) **서비스와 파드의 연결**:
    
- **파드**는 **동적 IP 주소**를 가지고 있어, 파드가 **종료**되거나 **새로 시작**될 때 IP 주소가 **변경**
- 서비스는 **파드들의 집합을 나타내는 추상화**로, **고정된 IP 주소**를 제공. 클러스터 내의 다른 파드나 외부에서 **변경되지 않는 IP 주소로 접근**할 수 있습니다.
    
1) **클러스터 내 트래픽 라우팅**:
    
- 클러스터 내에서 **서비스**는 **고정된 IP**를 통해 들어오는 트래픽을 **연관된 파드들로 분배.** 이때 `kube-proxy`가 **트래픽 라우팅**을 담당하며, **iptables** 또는 **ipvs**를 사용하여 서비스 IP로 들어오는 요청을 **파드로 전달**.
    - `kube-proxy`는 파드에 **네트워크 트래픽을 분배**하고, 여러 파드로 **로드 밸런싱**을 수행
    
2) **외부 트래픽 처리**:
    
    - **NodePort**나 **LoadBalancer** 서비스 유형은 외부 트래픽을 **클러스터로 유도**하고, 트래픽을 **적절한 파드로 라우팅**
    - **NodePort**는 클러스터 외부에서 **특정 포트**를 통해 접근할 수 있도록 함
    - **LoadBalancer**는 **외부 로드밸런서를 사용**하여 클러스터 외부에서 트래픽을 받아 파드들로 분배
    
3) **DNS를 통한 서비스 접근**:
    
    - 서비스는 **쿠버네티스 내부 DNS**에 등록. 다른 파드는 **서비스 이름**을 사용하여 **DNS**를 통해 해당 서비스의 **IP 주소를 찾고** 요청을 보냄
    - 예를 들어, `my-service.default.svc.cluster.local`을 사용하여 `my-service`라는 서비스에 접근할 수 있음
    
4) **서비스와 파드 간의 관계**:
    
    - 서비스는 **파드를 선택하기 위해 라벨 셀렉터**(label selector)를 사용하여 트래픽을 분배할 파드를 결정합. 예를 들어, 서비스는 **`app=web`** 라벨을 가진 파드로 트래픽을 분배할 수 있음
    - 쿠버네티스는 **파드의 상태**(예: 준비 완료)를 모니터링하여, 준비되지 않은 파드에는 트래픽을 보내지 않도록 함



### 오늘의 회고
- 오늘은 쿠버네티스 인그레스까지 실습을 하려고 했는데, 서비스 실습이 생각보다 오래 걸려서 서비스 실습 + 잡,크론잡 실습 조금 진행했다. 그냥 금방금방 하고 넘어갈 수도 있겠지만, 이왕 하는 김에 제대로 쿠버네티스의 구조와 순서를 이해하고 싶어서 개념 정리를 열심히 진행했다. 덕분에 쿠버네티스 구조를 한층 더 이해할 수 있게된 것 같아 뿌듯하다 ^^ 물론, 뒤에 남은 실습들이 있기 때문에 힘내서 따라가야한다. 화이팅~!!

### 참고 자료 및 링크
- x
